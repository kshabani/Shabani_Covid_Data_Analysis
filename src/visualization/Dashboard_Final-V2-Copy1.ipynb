{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda environment: general-python\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Update Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Branch Paths : b''\n",
      "INFO:root:File Update : b'Already up to date.\\n'\n",
      "WARNING:root:Full Data Successfully downloaded!\n",
      "WARNING:root:SIR Dataframe generated! \n"
     ]
    }
   ],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/data/get_data.py\n",
    "import subprocess\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    logging.info(\"Branch Paths : \" + str(error))\n",
    "    logging.info(\"File Update : \" + str(out))\n",
    "    logging.warning(\"Full Data Successfully downloaded!\")\n",
    "\n",
    "def COVID_SIR_DATA():\n",
    "    data_path = '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path).copy()\n",
    "    pd_raw.drop([\"Province/State\",\"Lat\",\"Long\"],axis=1,inplace=True)\n",
    "    country_list = list(pd_raw['Country/Region'].unique())\n",
    "    df = pd.DataFrame([])\n",
    "    \n",
    "    for each in country_list:\n",
    "        series = pd.Series(pd_raw[pd_raw['Country/Region'] == each].sum(), name = each)\n",
    "        df[each] = series\n",
    "    df.drop('Country/Region',axis=0,inplace=True)\n",
    "    pd.to_pickle(df,'/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_SIR.pkl')\n",
    "    logging.warning(\"SIR Dataframe generated! \")\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    COVID_SIR_DATA()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:the dates are: 0       2020-01-22\n",
      "1       2020-01-22\n",
      "2       2020-01-22\n",
      "3       2020-01-22\n",
      "4       2020-01-22\n",
      "           ...    \n",
      "52397   2020-08-05\n",
      "52398   2020-08-05\n",
      "52399   2020-08-05\n",
      "52400   2020-08-05\n",
      "52401   2020-08-05\n",
      "Name: date, Length: 52402, dtype: datetime64[ns]\n",
      "WARNING:root:Relational data structure generated !\n",
      "INFO:root: Number of rows stored: 52402\n"
     ]
    }
   ],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country'])                                 .T                                                              .stack(level=[0,1])                                             .reset_index()                                                  .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    logging.info(\"the dates are: {}\".format(pd_relational_model.date))\n",
    "\n",
    "    pd_relational_model.to_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    \n",
    "    logging.warning(\"Relational data structure generated !\")\n",
    "    logging.info(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:The dates are 0       2020-01-22\n",
      "1       2020-01-22\n",
      "2       2020-01-22\n",
      "3       2020-01-22\n",
      "4       2020-01-22\n",
      "           ...    \n",
      "89039   2020-08-05\n",
      "89040   2020-08-05\n",
      "89041   2020-08-05\n",
      "89042   2020-08-05\n",
      "89043   2020-08-05\n",
      "Name: date, Length: 89044, dtype: datetime64[ns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6622dd15af9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mpd_result_larg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_filtered_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_JH_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mpd_result_larg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_doubling_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_result_larg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mpd_result_larg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_doubling_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_result_larg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'confirmed_filtered'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6622dd15af9f>\u001b[0m in \u001b[0;36mcalc_doubling_rate\u001b[0;34m(df_input, filter_on)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mmust_contain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_on\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mmust_contain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' Erro in calc_filtered_data not all columns in data frame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mpd_DR_result\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrolling_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# %load /mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/src/features/build_features.py\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "def make_relatinoal_data_struture():\n",
    "    path_save='/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_relational_confirmed.csv'\n",
    "    data_path = '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path).copy()\n",
    "    \n",
    "    pd_data_base = pd_raw.rename(columns={'Country/Region':'country', 'Province/State':'state'})\n",
    "    pd_data_base = pd_data_base.drop(['Lat','Long'], axis=1)\n",
    "    \n",
    "    test_pd = pd_data_base.set_index(['state', 'country']).T\n",
    "    pd_relational_model =test_pd.stack(level=[0,1]).reset_index().rename(columns=                                             {'level_0':'date',0:'confirmed'})\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "    logging.info(\"The dates are {}\".format(pd_relational_model.date))\n",
    "    pd_relational_model.to_csv(path_save, sep=';')\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[column+'_filtered']=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    pd_filtered_result=df_input[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter).reset_index()\n",
    "    df_output=pd.merge(df_input,pd_filtered_result[['index',filter_on+'_filtered']],on=['index'],how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',filter_on+'_DR']],on=['index'],how='left')\n",
    "    df_output.to_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_final_set_.csv',sep=';',index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_relational_confirmed.csv'\n",
    "    make_relatinoal_data_struture()\n",
    "    pd_JH_data=pd.read_csv(path,sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).reset_index().copy()\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     24,
     29,
     33,
     39
    ]
   },
   "outputs": [],
   "source": [
    "# %load /mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/src/visualization/dashboard_V2.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "from datetime import datetime\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "path1 = '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_final_set_.csv'\n",
    "path2 = '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_SIR.pkl'\n",
    "\n",
    "#df_input_large = pd.read_csv(path1,sep=';')\n",
    "df_input_large = pd.read_pickle(path1)\n",
    "df_analyse = pd.read_pickle(path2)\n",
    "\n",
    "colors = {'background': '#111111', 'text': '#7FDBFF'}\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "tab_1 = dcc.Tab(label='Analysis of Rate of infection', value='tab_1', children=[\n",
    "    html.H3(\"Countries\"), \n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[{'label': each, 'value': each} for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany', 'Italy'],  # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "    html.H3(\"Type of Graph\"),\n",
    "    dcc.Dropdown(\n",
    "        id='doubling_time',\n",
    "        options=[\n",
    "            {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "            {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "            {'label': 'Timeline Doubling Rate', 'value': 'doubling_rate'},\n",
    "            {'label': 'Timeline Doubling Rate Filtered', 'value': 'doubling_rate_filtered'},\n",
    "        ],\n",
    "        value='confirmed',\n",
    "        multi=False\n",
    "    ),\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "            Regarding the filtration of data and doubling rate calculation, the following techniques are used.\n",
    "                * The savgol signal filtration was used to filter the data mainly to smoothen reporting delays and \n",
    "                 human errors in reporting.A window  size of five data points was used.\n",
    "                *  The doubling rate was calculated via rolling regression with a window size of 3 days back. \n",
    "    ''')\n",
    "]\n",
    "                )\n",
    "\n",
    "tab_2 = dcc.Tab(label='SIR Model Demonstration', value='tab_2',children=[\n",
    "html.H3(\"N0: max susceptible population\") ,   \n",
    "dcc.Slider(\n",
    "id='N0s',\n",
    "min=0,\n",
    "max=1000000,\n",
    "step=10000,\n",
    "value=100000,\n",
    " marks={i: '{}'.format(i) for i in list(range(0,1000000,100000)) }\n",
    "),\n",
    "      \n",
    "html.H3(\"Gamma values: recovery rate\") ,   \n",
    "dcc.Slider(\n",
    "id='gammar',\n",
    "min=0,\n",
    "max=1,\n",
    "step=0.1,\n",
    "value=0.1,\n",
    " marks={i: '{}'.format(i) for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    "),html.H3(\"Beta min-max :infection spread dynamics\") \n",
    " ,\n",
    "    dcc.RangeSlider(\n",
    "    id='betas',\n",
    "    min=0,\n",
    "    max=1,\n",
    "    step=0.001,\n",
    "    value=[0.1, 0.4],\n",
    "    marks={i: '{}'.format(i) for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}\n",
    ")\n",
    "    ,\n",
    "    html.H3(\"Countries\")\n",
    "    ,\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down2',\n",
    "        options=[{'label': each, 'value': each} for each in df_input_large['country'].unique()],\n",
    "        value='Germany',  # which are pre-selected\n",
    "        multi=False\n",
    "    )\n",
    "])\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [html.Center(html.H1('Covid19 Data Analysis')), dcc.Tabs(id='my_tabs', value='tab_1', children=[tab_1, tab_2]),\n",
    "     html.Div(html.Center([dcc.Graph(figure=fig, id='main_window_slope')]))])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('my_tabs', 'value'),\n",
    "     Input('gammar', 'value'),\n",
    "     Input('betas', 'value'),\n",
    "     Input('N0s', 'value'),\n",
    "     Input('country_drop_down', 'value'),\n",
    "     Input('country_drop_down2', 'value'),\n",
    "     Input('doubling_time', 'value')])\n",
    "def update_figure(tab,gammas,betas,N0_val,country_list,sir_country_list,show_doubling):\n",
    "    \n",
    "  \n",
    "    ind = df_analyse[df_analyse[sir_country_list] == 0].index.get_loc(df_analyse[df_analyse[sir_country_list]                                ==0].index.max()) +1\n",
    "    ydata = df_analyse[sir_country_list][ind+1:]\n",
    "    t = np.arange(len(ydata))\n",
    "    N0 = N0_val  # max susceptible population\n",
    "    I0 = ydata[0]\n",
    "    S0 = N0 - I0\n",
    "    R0 = 0    \n",
    "    gamma = gammas\n",
    "    \n",
    "    def SIR_model(SIR, beta, gamma):\n",
    "        ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta:\n",
    "\n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "\n",
    "        '''\n",
    "\n",
    "        S, I, R = SIR\n",
    "        dS_dt = -beta * S * I / N0  # S*I is the\n",
    "        dI_dt = beta * S * I / N0 - gamma * I\n",
    "        dR_dt = gamma * I\n",
    "        return ([dS_dt, dI_dt, dR_dt])\n",
    "\n",
    "\n",
    "    def SIR_model_t(SIR, t, beta, gamma):\n",
    "        ''' Simple SIR model\n",
    "            S: susceptible population\n",
    "            t: time step, mandatory for integral.odeint\n",
    "            I: infected people\n",
    "            R: recovered people\n",
    "            beta:\n",
    "\n",
    "            overall condition is that the sum of changes (differnces) sum up to 0\n",
    "            dS+dI+dR=0\n",
    "            S+I+R= N (constant size of population)\n",
    "\n",
    "        '''\n",
    "\n",
    "        S, I, R = SIR\n",
    "        dS_dt = -beta * S * I / N0  # S*I is the\n",
    "        dI_dt = beta * S * I / N0 - gamma * I\n",
    "        dR_dt = gamma * I\n",
    "        return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "\n",
    "    def fit_odeint(x, beta, gamma):\n",
    "        \n",
    "        '''\n",
    "        helper function for the integration\n",
    "        '''\n",
    "        return integrate.odeint(SIR_model_t, (S0, I0, R0), t, args=(beta, gamma))[:, 1]\n",
    " \n",
    "    \n",
    "    if tab == 'tab_1':\n",
    "\n",
    "        if 'doubling_rate' in show_doubling:\n",
    "            my_yaxis = {'type': \"log\",\n",
    "                        'title': 'Approximated doubling rate over 3 days (larger numbers are better)'}\n",
    "        else:\n",
    "            my_yaxis = {'type': \"log\",\n",
    "                        'title': 'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "                        }\n",
    "\n",
    "        traces = []\n",
    "        for each in country_list:\n",
    "\n",
    "            df_plot = df_input_large[df_input_large['country'] == each]\n",
    "\n",
    "            if show_doubling == 'doubling_rate_filtered':\n",
    "                df_plot = df_plot[\n",
    "                    ['state', 'country', 'confirmed', 'confirmed_filtered', 'doubling_rate', 'doubling_rate_filtered',\n",
    "                     'date']].groupby(['country', 'date']).agg(np.mean).reset_index()\n",
    "            else:\n",
    "                df_plot = df_plot[\n",
    "                    ['state', 'country', 'confirmed', 'confirmed_filtered', 'doubling_rate', 'doubling_rate_filtered',\n",
    "                     'date']].groupby(['country', 'date']).agg(np.sum).reset_index()\n",
    "\n",
    "            traces.append(go.Scatter(x=df_plot.date,\n",
    "                                     y=df_plot[show_doubling],\n",
    "                                     mode='markers+lines',\n",
    "                                     opacity=0.9,\n",
    "                                     name=each)\n",
    "                          )\n",
    "            layout = go.Layout(\n",
    "                width=1280,\n",
    "                height=720,\n",
    "                plot_bgcolor=colors['background'],\n",
    "                paper_bgcolor=colors['background'],\n",
    "                font={'color': colors['text']},\n",
    "                xaxis={'title': 'Timeline',\n",
    "                       'tickangle': -45,\n",
    "                       'nticks': 20,\n",
    "                       'tickfont': dict(size=14, color=\"#7f7f7f\"),\n",
    "                       },\n",
    "                yaxis=my_yaxis\n",
    "            )\n",
    "\n",
    "        return dict(data=traces, layout=layout)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        ind = df_analyse[df_analyse[sir_country_list] ==                                                                     0].index.get_loc(df_analyse[df_analyse[sir_country_list] ==0].index.max()) +1\n",
    "\n",
    "        ydata = df_analyse[sir_country_list][ind:]\n",
    "        t = np.arange(len(ydata))\n",
    "\n",
    "        I0 = ydata[0]\n",
    "        S0 = N0 - I0\n",
    "        R0 = 0\n",
    "        \n",
    "        t_initial = 28\n",
    "        t_intro_measures = 14\n",
    "        t_hold = 21\n",
    "        t_relax = 21\n",
    "\n",
    "        beta_max = betas[1]\n",
    "        beta_min = betas[0]\n",
    "        \n",
    "      \n",
    "        popt, pcov = optimize.curve_fit(fit_odeint, t, ydata)\n",
    "        fitted = fit_odeint(t, *popt)\n",
    "\n",
    "        \n",
    "        pd_beta = np.concatenate((np.array(t_initial * [beta_max]),\n",
    "                                  np.linspace(beta_max, beta_min, t_intro_measures),\n",
    "                                  np.array(t_hold * [beta_min]),\n",
    "                                  np.linspace(beta_min, beta_max, t_relax),\n",
    "                                  ))\n",
    "        SIR = np.array([S0, I0, R0])\n",
    "        propagation_rates = pd.DataFrame(columns={'susceptible': S0,\n",
    "                                                  'infected': I0,\n",
    "                                                  'recoverd': R0})\n",
    "        for each_beta in pd_beta:\n",
    "            new_delta_vec = SIR_model(SIR, each_beta, gamma)\n",
    "\n",
    "            SIR = SIR + new_delta_vec\n",
    "\n",
    "            propagation_rates = propagation_rates.append({'susceptible': SIR[0],\n",
    "                                                          'infected': SIR[1],\n",
    "                                                          'recovered': SIR[2]}, ignore_index=True)\n",
    "        t_phases = np.array([t_initial, t_intro_measures, t_hold, t_relax]).cumsum()\n",
    "        fig = make_subplots(rows=2, cols=2, specs=[[{\"colspan\": 2}, None], [{\"colspan\": 2}, None]], subplot_titles=(\n",
    "            \"Fit of SIR model with fixed beta and gamma\",\n",
    "            'Szenario SIR simulations with fixed gamma and dynamic beta')\n",
    "                            )\n",
    "        trace11 = go.Scatter(x=t, y=ydata, mode='markers',name = 'True infected number')\n",
    "        trace22 = go.Scatter(x=t, y=fitted, mode='lines',name='fitted infected number')\n",
    "        trace111 = go.Scatter(x=propagation_rates.index, y=propagation_rates.infected, name='simlated infected', mode='lines',\n",
    "                              line=dict(width=5))\n",
    "        trace222 = go.Bar(x=np.arange(len(ydata)), y=ydata, name='current infected')\n",
    "\n",
    "        fig.add_trace(trace11, row=1, col=1)\n",
    "        fig.add_trace(trace22, row=1, col=1)\n",
    "        fig.add_trace(trace111, row=2, col=1)\n",
    "        fig.add_trace(trace222, row=2, col=1)\n",
    "\n",
    "        fig.update_yaxes(type='log', row=1, col=1,title_text='population infected')\n",
    "        fig.update_yaxes(type='log', row=2, col=1,title_text ='population infected')\n",
    "        \n",
    "        fig.update_xaxes(row=1,col=1,title_text = 'time in days')\n",
    "        fig.update_xaxes(row=2,col=1,title_text = 'time in days')\n",
    "        \n",
    "        fig.update_layout(plot_bgcolor=colors['background'],\n",
    "                          paper_bgcolor=colors['background'],\n",
    "                          font={'color': colors['text']})\n",
    "\n",
    "        return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
