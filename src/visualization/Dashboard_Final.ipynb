{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#  Update Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : b''\n",
      "out : b'Already up to date.\\n'\n",
      " Number of regions rows: 412\n"
     ]
    }
   ],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/data/get_data.py\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "                         cwd = os.path.dirname( '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/' ),\n",
    "                         shell = True,\n",
    "                         stdout = subprocess.PIPE,\n",
    "                         stderr = subprocess.PIPE )\n",
    "    (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    print(\"Error : \" + str(error))\n",
    "    print(\"out : \" + str(out))\n",
    "\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions / Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_johns_hopkins()\n",
    "    get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#  Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/data/process_JH_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country'])                                 .T                                                              .stack(level=[0,1])                                             .reset_index()                                                  .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#  Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/features/build_features.py\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function (data structure kept)\n",
    "\n",
    "        parameters:\n",
    "        ----------\n",
    "        df_input : pandas.series\n",
    "        column : str\n",
    "        window : int\n",
    "            used data points to calculate the filter result\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_result: pd.DataFrame\n",
    "            the index of the df_input has to be preserved in result\n",
    "    '''\n",
    "\n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "\n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "\n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           window, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[column+'_filtered']=result\n",
    "    return df_result\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' Rolling Regression to approximate the doubling time'\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        col: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        result: pd.DataFrame\n",
    "    '''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    pd_filtered_result=df_input[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter).reset_index()\n",
    "    df_output=pd.merge(df_input,pd_filtered_result[['index',filter_on+'_filtered']],on=['index'],how='left')\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',filter_on+'_DR']],on=['index'],how='left')\n",
    "    return df_output\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "    \n",
    "    pd_JH_data=pd.read_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).reset_index().copy()\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "    print(pd_result_larg.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     24,
     29,
     33,
     39
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on http://127.0.0.1:8050/\n",
      "Debugger PIN: 713-910-554\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sem/miniconda3/envs/general-python/lib/python3.8/site-packages/scipy/integrate/odepack.py:248: ODEintWarning:\n",
      "\n",
      "Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %load /media/sem/HDD/Home_Programming/Git/ads_covid-19-sem/src/visualization/dashboard.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "from datetime import datetime\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "df_input_large = pd.read_csv('/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_final_set.csv',\n",
    "                             sep=';')\n",
    "df_analyse = pd.read_csv(\n",
    "    '/mnt/368AE7F88AE7B313/Files_Programming/Git/ads_covid-19-sem/data/processed/COVID_small_flat_table.csv', sep=';')\n",
    "\n",
    "colors = {'background': '#111111', 'text': '#7FDBFF'}\n",
    "\n",
    "N0 = 1000000  # max susceptible population\n",
    "beta = 0.4  # infection spread dynamics\n",
    "gamma = 0.1  # recovery rate\n",
    "\n",
    "\n",
    "def SIR_model(SIR, beta, gamma):\n",
    "    ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta:\n",
    "\n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "\n",
    "    '''\n",
    "\n",
    "    S, I, R = SIR\n",
    "    dS_dt = -beta * S * I / N0  # S*I is the\n",
    "    dI_dt = beta * S * I / N0 - gamma * I\n",
    "    dR_dt = gamma * I\n",
    "    return ([dS_dt, dI_dt, dR_dt])\n",
    "\n",
    "\n",
    "def SIR_model_t(SIR, t, beta, gamma):\n",
    "    ''' Simple SIR model\n",
    "        S: susceptible population\n",
    "        t: time step, mandatory for integral.odeint\n",
    "        I: infected people\n",
    "        R: recovered people\n",
    "        beta:\n",
    "\n",
    "        overall condition is that the sum of changes (differnces) sum up to 0\n",
    "        dS+dI+dR=0\n",
    "        S+I+R= N (constant size of population)\n",
    "\n",
    "    '''\n",
    "\n",
    "    S, I, R = SIR\n",
    "    dS_dt = -beta * S * I / N0  # S*I is the\n",
    "    dI_dt = beta * S * I / N0 - gamma * I\n",
    "    dR_dt = gamma * I\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "\n",
    "def fit_odeint(x, beta, gamma):\n",
    "    '''\n",
    "    helper function for the integration\n",
    "    '''\n",
    "    return integrate.odeint(SIR_model_t, (S0, I0, R0), t, args=(beta, gamma))[:, 1]\n",
    "\n",
    "\n",
    "ydata = np.array(df_analyse.Germany[35:])\n",
    "t = np.arange(len(ydata))\n",
    "\n",
    "I0 = ydata[0]\n",
    "S0 = N0 - I0\n",
    "R0 = 0\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "tab_1 = dcc.Tab(label='Analysis of Rate of infection', value='tab_1', children=[\n",
    "\n",
    "    dcc.Dropdown(\n",
    "        id='country_drop_down',\n",
    "        options=[{'label': each, 'value': each} for each in df_input_large['country'].unique()],\n",
    "        value=['US', 'Germany', 'Italy'],  # which are pre-selected\n",
    "        multi=True\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='doubling_time',\n",
    "        options=[\n",
    "            {'label': 'Timeline Confirmed ', 'value': 'confirmed'},\n",
    "            {'label': 'Timeline Confirmed Filtered', 'value': 'confirmed_filtered'},\n",
    "            {'label': 'Timeline Doubling Rate', 'value': 'doubling_rate'},\n",
    "            {'label': 'Timeline Doubling Rate Filtered', 'value': 'doubling_rate_filtered'},\n",
    "        ],\n",
    "        value='confirmed',\n",
    "        multi=False\n",
    "    ),\n",
    "    dcc.Markdown('''\n",
    "            Regarding the filtration of data and doubling rate calculation, the following techniques are used.\n",
    "                * The savgol signal filtration was used to filter the data mainly to smoothen reporting delays and \n",
    "                 human errors in reporting.A window  size of five data points was used.\n",
    "                *  The doubling rate was calculated via rolling regression with a window size of 3 days back. \n",
    "    ''')\n",
    "]\n",
    "                )\n",
    "\n",
    "tab_2 = dcc.Tab(label='SIR Model Demonstration For Germany', value='tab_2',children=[\n",
    "            dcc.Markdown('''\n",
    "                * For the static case we have that:\n",
    "                    * beta is approximately 0.35424\n",
    "                    * gamma is approximately 0.1604\n",
    "                * For the dynamic case:\n",
    "                    * gamma is held constant at 0.1\n",
    "                    * with beta allowed to have a maximum value of 0.4 and a minimum of 0.11            \n",
    "            ''')\n",
    "])\n",
    "\n",
    "app.layout = html.Div(\n",
    "    [html.Center(html.H1('Covid19 Data Analysis')), dcc.Tabs(id='my_tabs', value='tab_1', children=[tab_1, tab_2]),\n",
    "     html.Div(html.Center([dcc.Graph(figure=fig, id='main_window_slope')]))])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('my_tabs', 'value'),\n",
    "     Input('country_drop_down', 'value'),\n",
    "     Input('doubling_time', 'value')])\n",
    "def update_figure(tab, country_list, show_doubling):\n",
    "    if tab == 'tab_1':\n",
    "\n",
    "        if 'doubling_rate' in show_doubling:\n",
    "            my_yaxis = {'type': \"log\",\n",
    "                        'title': 'Approximated doubling rate over 3 days (larger numbers are better)'}\n",
    "        else:\n",
    "            my_yaxis = {'type': \"log\",\n",
    "                        'title': 'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "                        }\n",
    "\n",
    "        traces = []\n",
    "        for each in country_list:\n",
    "\n",
    "            df_plot = df_input_large[df_input_large['country'] == each]\n",
    "\n",
    "            if show_doubling == 'doubling_rate_filtered':\n",
    "                df_plot = df_plot[\n",
    "                    ['state', 'country', 'confirmed', 'confirmed_filtered', 'doubling_rate', 'doubling_rate_filtered',\n",
    "                     'date']].groupby(['country', 'date']).agg(np.mean).reset_index()\n",
    "            else:\n",
    "                df_plot = df_plot[\n",
    "                    ['state', 'country', 'confirmed', 'confirmed_filtered', 'doubling_rate', 'doubling_rate_filtered',\n",
    "                     'date']].groupby(['country', 'date']).agg(np.sum).reset_index()\n",
    "\n",
    "            traces.append(go.Scatter(x=df_plot.date,\n",
    "                                     y=df_plot[show_doubling],\n",
    "                                     mode='markers+lines',\n",
    "                                     opacity=0.9,\n",
    "                                     name=each)\n",
    "                          )\n",
    "            layout = go.Layout(\n",
    "                width=1280,\n",
    "                height=720,\n",
    "                plot_bgcolor=colors['background'],\n",
    "                paper_bgcolor=colors['background'],\n",
    "                font={'color': colors['text']},\n",
    "                xaxis={'title': 'Timeline',\n",
    "                       'tickangle': -45,\n",
    "                       'nticks': 20,\n",
    "                       'tickfont': dict(size=14, color=\"#7f7f7f\"),\n",
    "                       },\n",
    "                yaxis=my_yaxis\n",
    "            )\n",
    "\n",
    "        return dict(data=traces, layout=layout)\n",
    "\n",
    "    else:\n",
    "\n",
    "        ydata = np.array(df_analyse.Germany[35:])\n",
    "        t = np.arange(len(ydata))\n",
    "        I0 = ydata[0]\n",
    "        S0 = N0 - I0\n",
    "        R0 = 0\n",
    "        popt, pcov = optimize.curve_fit(fit_odeint, t, ydata)\n",
    "        fitted = fit_odeint(t, *popt)\n",
    "\n",
    "        t_initial = 28\n",
    "        t_intro_measures = 14\n",
    "        t_hold = 21\n",
    "        t_relax = 21\n",
    "\n",
    "        beta_max = 0.4\n",
    "        beta_min = 0.11\n",
    "        gamma = 0.1\n",
    "        pd_beta = np.concatenate((np.array(t_initial * [beta_max]),\n",
    "                                  np.linspace(beta_max, beta_min, t_intro_measures),\n",
    "                                  np.array(t_hold * [beta_min]),\n",
    "                                  np.linspace(beta_min, beta_max, t_relax),\n",
    "                                  ))\n",
    "        SIR = np.array([S0, I0, R0])\n",
    "        propagation_rates = pd.DataFrame(columns={'susceptible': S0,\n",
    "                                                  'infected': I0,\n",
    "                                                  'recoverd': R0})\n",
    "        for each_beta in pd_beta:\n",
    "            new_delta_vec = SIR_model(SIR, each_beta, gamma)\n",
    "\n",
    "            SIR = SIR + new_delta_vec\n",
    "\n",
    "            propagation_rates = propagation_rates.append({'susceptible': SIR[0],\n",
    "                                                          'infected': SIR[1],\n",
    "                                                          'recovered': SIR[2]}, ignore_index=True)\n",
    "        t_phases = np.array([t_initial, t_intro_measures, t_hold, t_relax]).cumsum()\n",
    "        fig = make_subplots(rows=2, cols=2, specs=[[{\"colspan\": 2}, None], [{\"colspan\": 2}, None]], subplot_titles=(\n",
    "            \"Fit of SIR model for Germany cases with fixed beta and gamma\",\n",
    "            'Szenario SIR simulations with fixed gamma and dynamic beta')\n",
    "                            )\n",
    "        trace11 = go.Scatter(x=t, y=ydata, mode='markers',name = 'True infected number')\n",
    "        trace22 = go.Scatter(x=t, y=fitted, mode='lines',name='fitted infected number')\n",
    "        trace111 = go.Scatter(x=propagation_rates.index, y=propagation_rates.infected, name='simlated infected', mode='lines',\n",
    "                              line=dict(width=5))\n",
    "        trace222 = go.Bar(x=np.arange(len(ydata)), y=ydata, name='current infected germany')\n",
    "\n",
    "        fig.add_trace(trace11, row=1, col=1)\n",
    "        fig.add_trace(trace22, row=1, col=1)\n",
    "        fig.add_trace(trace111, row=2, col=1)\n",
    "        fig.add_trace(trace222, row=2, col=1)\n",
    "\n",
    "        fig.update_yaxes(type='log', row=1, col=1,title_text='population infected')\n",
    "        fig.update_yaxes(type='log', row=2, col=1,title_text ='population infected')\n",
    "        \n",
    "        fig.update_xaxes(row=1,col=1,title_text = 'time in days')\n",
    "        fig.update_xaxes(row=2,col=1,title_text = 'time in days')\n",
    "        \n",
    "        fig.update_layout(plot_bgcolor=colors['background'],\n",
    "                          paper_bgcolor=colors['background'],\n",
    "                          font={'color': colors['text']})\n",
    "\n",
    "        return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
